---
published: false
---
Tracking in AR



AR relies on computer vision to see the world and recognise the objects in it. The first step in the computer vision process is getting the visual information, the environment around the hardware to the brain inside the device. The process of scanning, recognising, segmenting, and analysing environmental information is called tracking, in immersive technologies. For AR, there’s two ways tracking happens, inside-out tracking and outside-in tracking.

## Outside-In Tracking
With Outside-in Tracking, cameras or sensors aren’t housed within the AR device itself. Instead, they’re mounted elsewhere in the space. Typically, mounted on walls or on stands to have an unobstructed view of the AR device. They then feed information to the AR device directly or through a computer. Outside-in Tracking overcomes some of the space and power issues that can occur with AR devices. The external cameras or sensors can be as large as you want, at least theoretically. You don’t have to worry about people wearing them on their faces or carrying them in their pockets. But what you gain in function, you lose in portability. If your headset loses connection to the outside sensors for even a moment, then they can lose tracking. The visuals will suffer breaking immersion.

## Inside-Out Tracking
With inside-out tracking, cameras and sensors are built right into the body of the device. Smartphones are the most obvious example of this type of tracking. They have cameras for seeing and processors for thinking in one wireless battery-powered portable device. On the AR headset side Microsoft’s HoloLens is another device that uses inside-out tracking in AR. But all that hardware takes up space, power, and generates heat. The true power of standalone AR devices will emerge when they become as ubiquitous and as useful as smartphones.